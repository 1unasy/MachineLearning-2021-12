{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비지도학습 감성분석 - Lexicon 기반"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### < Wordnet Synset 및 Sentiwordnet SentiSynset 클래스 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 워드넷(Wordnet) : 영어의 의미 어휘목록\n",
    "    - 워드넷은 영어 단어를 'synset'이라는 유의어 집단으로 분류하여 간략하고 일반적인 정의를 제공하고, 이러한 어휘목록 사이의 다양한 의미 관계를 기록한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 워드넷 synset\n",
    "    ``` \n",
    "        - synset.name() : 단어 의미 목록(명) \n",
    "            - <ex> present.n.01\n",
    "        - synset.definition() : 정의\n",
    "        - synset.pos() : 품사\n",
    "        - synset.example() : 예제 문장\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※ 총 **5가지의 품사**(Part-of-speech, POS)가 존재한다.\n",
    "```    \n",
    "- n : noun                  (명사)\n",
    "- v : verb                  (동사)\n",
    "- a : adjective             (형용사)\n",
    "- s : adjective satellite   (반의어가 존재하지 않는 단어)\n",
    "- r : adverb                (부사)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sentiwordnet\n",
    "    - Wordnet과 굉장히 유사한데, 감정 지수와 객관성 지수를 가지고 있다. \n",
    "    - 감정 지수는 긍정 / 부정으로 나뉘고, 객관성 지수는 감성적이지 않으면 1이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Wordnet Synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet # wordnet : 어휘사전\n",
    "\n",
    "term = 'present'\n",
    "synsets = wordnet.synsets(term) # present 단어 의미 목록 도출"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### wordnet 계속 입력하기 힘드므로, 처음 패키지 임포트 시 `from nltk.corpus import wordnet as wn` 으로 해도 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 18)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# present 단어 의미 목록 형태 / 단어의 의미 갯수\n",
    "type(synsets), len(synsets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('present.n.01'), Synset('present.n.02'), Synset('present.n.03'), Synset('show.v.01'), Synset('present.v.02'), Synset('stage.v.01'), Synset('present.v.04'), Synset('present.v.05'), Synset('award.v.01'), Synset('give.v.08'), Synset('deliver.v.01'), Synset('introduce.v.01'), Synset('portray.v.04'), Synset('confront.v.03'), Synset('present.v.12'), Synset('salute.v.06'), Synset('present.a.01'), Synset('present.a.02')]\n"
     ]
    }
   ],
   "source": [
    "print(synsets) # synsets : 단어의 모든 의미들 - 객체들의 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Name: present.n.01 ----\n",
      "POS:  noun.time\n",
      "정의:  the period of time that is happening now; any continuous stretch of time including the moment of speech\n",
      "표제어:  ['present', 'nowadays']\n",
      "---- Name: present.n.02 ----\n",
      "POS:  noun.possession\n",
      "정의:  something presented as a gift\n",
      "표제어:  ['present']\n",
      "---- Name: present.n.03 ----\n",
      "POS:  noun.communication\n",
      "정의:  a verb tense that expresses actions or states at the time of speaking\n",
      "표제어:  ['present', 'present_tense']\n",
      "---- Name: show.v.01 ----\n",
      "POS:  verb.perception\n",
      "정의:  give an exhibition of to an interested audience\n",
      "표제어:  ['show', 'demo', 'exhibit', 'present', 'demonstrate']\n",
      "---- Name: present.v.02 ----\n",
      "POS:  verb.communication\n",
      "정의:  bring forward and present to the mind\n",
      "표제어:  ['present', 'represent', 'lay_out']\n"
     ]
    }
   ],
   "source": [
    "for synset in synsets[:5]:\n",
    "    print(f'---- Name: {synset.name()} ----') # 단어 의미 목록 _ 단어.품사.번호\n",
    "    print('POS: ', synset.lexname())    # 단어의 품사.목록\n",
    "    print('정의: ', synset.definition())    # 단어의 정의\n",
    "    print('표제어: ', synset.lemma_names()) # 동의어 단어 집합"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 어휘간의 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tiger.n.01 a fierce or audacious person\n",
      "tiger.n.02 large feline of forests in most of Asia having a tawny coat with black stripes; endangered\n"
     ]
    }
   ],
   "source": [
    "for synset in wordnet.synsets('tiger'):\n",
    "    print(synset.name(), synset.definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어, 품사를 아는 경우에는 synset()\n",
    "tiger = wordnet.synset('tiger.n.02')\n",
    "tree = wordnet.synset('tree.n.01')\n",
    "lion = wordnet.synset('lion.n.01')\n",
    "cat = wordnet.synset('cat.n.01')\n",
    "dog = wordnet.synset('dog.n.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3333333333333333, 0.16666666666666666, 0.07142857142857142)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어간의 유사도 - 단어.path_similarity(비교할 단어)\n",
    "# wordnet.synset() 객체로 만든 단어를 입력해야 함\n",
    "tiger.path_similarity(lion), tiger.path_similarity(dog), tiger.path_similarity(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5개 단어간의 유사도\n",
    "similarities = []\n",
    "entities = [tree, lion, tiger, cat, dog]\n",
    "for entity in entities:\n",
    "    similarity = [entity.path_similarity(another) for another in entities]\n",
    "    similarities.append(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree</th>\n",
       "      <th>lion</th>\n",
       "      <th>tiger</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       tree      lion     tiger       cat       dog\n",
       "0  1.000000  0.071429  0.071429  0.076923  0.125000\n",
       "1  0.071429  1.000000  0.333333  0.250000  0.166667\n",
       "2  0.071429  0.333333  1.000000  0.250000  0.166667\n",
       "3  0.076923  0.250000  0.250000  1.000000  0.200000\n",
       "4  0.125000  0.166667  0.166667  0.200000  1.000000"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(similarities, columns=['tree', 'lion', 'tiger', 'cat', 'dog'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ※ 인덱스 변경 : `set_index(keys=[k1, k2, ...], inplace=True/False, drop=True/False)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree</th>\n",
       "      <th>lion</th>\n",
       "      <th>tiger</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tree</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lion</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiger</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           tree      lion     tiger       cat       dog\n",
       "tree   1.000000  0.071429  0.071429  0.076923  0.125000\n",
       "lion   0.071429  1.000000  0.333333  0.250000  0.166667\n",
       "tiger  0.071429  0.333333  1.000000  0.250000  0.166667\n",
       "cat    0.076923  0.250000  0.250000  1.000000  0.200000\n",
       "dog    0.125000  0.166667  0.166667  0.200000  1.000000"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 유사도 비교 용이하게 하기 위해 인덱스 변경\n",
    "index = ['tree', 'lion', 'tiger', 'cat', 'dog']\n",
    "df.set_index(keys=[index], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Sentiwordnet SentiSynset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SentiSynset 객체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet\n",
    "\n",
    "senti_synsets = list(sentiwordnet.senti_synsets('slow'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### sentiwordnet 계속 입력하기 힘드므로, 처음 패키지 임포트 시 `from nltk.corpus import sentiwordnet as sw` 으로 해도 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "11\n",
      "[SentiSynset('decelerate.v.01'), SentiSynset('slow.v.02'), SentiSynset('slow.v.03'), SentiSynset('slow.a.01'), SentiSynset('slow.a.02'), SentiSynset('dense.s.04'), SentiSynset('slow.a.04'), SentiSynset('boring.s.01'), SentiSynset('dull.s.08'), SentiSynset('slowly.r.01'), SentiSynset('behind.r.03')]\n"
     ]
    }
   ],
   "source": [
    "print(type(senti_synsets))\n",
    "print(len(senti_synsets))\n",
    "print(senti_synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "9\n",
      "[SentiSynset('father.n.01'), SentiSynset('forefather.n.01'), SentiSynset('father.n.03'), SentiSynset('church_father.n.01'), SentiSynset('father.n.05'), SentiSynset('father.n.06'), SentiSynset('founder.n.02'), SentiSynset('don.n.03'), SentiSynset('beget.v.01')]\n"
     ]
    }
   ],
   "source": [
    "senti_synsets = list(sentiwordnet.senti_synsets('father'))\n",
    "print(type(senti_synsets))\n",
    "print(len(senti_synsets))\n",
    "print(senti_synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 1.0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# father 단어의 긍정감성 지수, 부정감성 지수, 객관성 지수\n",
    "# 긍정도 부정도 아닌 객관성을 지닌 단어\n",
    "father = sentiwordnet.senti_synset('father.n.01')\n",
    "father.pos_score(), father.neg_score(), father.obj_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 1.0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mother 단어의 긍정감성 지수, 부정감성 지수, 객관성 지수\n",
    "# 긍정도 부정도 아닌 객관성을 지닌 단어\n",
    "mother = sentiwordnet.senti_synset('mother.n.01')\n",
    "mother.pos_score(), mother.neg_score(), mother.obj_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.875, 0.125, 0.0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fabulous 단어의 긍정감성 지수, 부정감성 지수, 객관성 지수\n",
    "# 의미 : 엄청난, 굉장한 --> 긍정감성 지수 (0.875-0.125=0.75)\n",
    "fabulous = sentiwordnet.senti_synset('fabulous.a.01')\n",
    "fabulous.pos_score(), fabulous.neg_score(), fabulous.obj_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SentiSynset('just.a.01'),\n",
       " SentiSynset('equitable.a.01'),\n",
       " SentiSynset('fair.a.01'),\n",
       " SentiSynset('good.s.07'),\n",
       " SentiSynset('merely.r.01'),\n",
       " SentiSynset('precisely.r.01'),\n",
       " SentiSynset('just.r.03'),\n",
       " SentiSynset('just.r.04'),\n",
       " SentiSynset('barely.r.01'),\n",
       " SentiSynset('just.r.06')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sentiwordnet.senti_synsets('just'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.125, 0.0, 0.875)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precisely 단어의 긍정감성 지수, 부정감성 지수, 객관성 지수\n",
    "precisely = sentiwordnet.senti_synset('precisely.r.01')\n",
    "precisely.pos_score(), precisely.neg_score(), precisely.obj_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 1.0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# work 단어의 긍정감성 지수, 부정감성 지수, 객관성 지수\n",
    "work = sentiwordnet.senti_synset('work.v.01')\n",
    "work.pos_score(), work.neg_score(), work.obj_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0, 1.0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# hit 단어의 긍정감성 지수, 부정감성 지수, 객관성 지수\n",
    "hit = sentiwordnet.senti_synset('hit.v.01')\n",
    "hit.pos_score(), hit.neg_score(), hit.obj_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('n', 'a', 'r', 'v')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordnet.NOUN, wordnet.ADJ, wordnet.ADV, wordnet.VERB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 감성지수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It', \"'s\", 'good', 'to', 'see', 'you', 'again', '.']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag # 단어 토큰화, 단어 품사 태그\n",
    "\n",
    "sentence = \"It's good to see you again.\"\n",
    "word_list = word_tokenize(sentence) # 단어 토큰화\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('It', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('good', 'JJ'),\n",
       " ('to', 'TO'),\n",
       " ('see', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('again', 'RB'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(word_list)  # 단어 품사 태그 # 튜플 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag = ('good', 'JJ')\n",
    "tag[1].startswith('J') # str.startswith(str or tuple) --> return: True/False - 지정한 문자열로 시작하면 T 아니면 F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_tag -> wordnet 으로 바꿔주는 함수\n",
    "def penn_to_wn(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    return None    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It PRP\n",
      "'s VBZ\n",
      "good JJ\n",
      "to TO\n",
      "see VB\n",
      "you PRP\n",
      "again RB\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "for word, tag in pos_tag(word_list):\n",
    "    print(word, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It None\n",
      "'s v\n",
      "good a\n",
      "to None\n",
      "see v\n",
      "you None\n",
      "again r\n",
      ". None\n"
     ]
    }
   ],
   "source": [
    "# pos_tag -> wordnet 으로 바꿔주는 함수 사용\n",
    "for word, tag in pos_tag(word_list):\n",
    "    print(word, penn_to_wn(tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good', 'see', 'you', 'again']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentence 로부터 Senti_Synset 객체를 만드는 과정\n",
    "sentence = \"It's good to see you again.\"\n",
    "word_list = [word for word in word_tokenize(sentence) if len(word) > 2] # 단어의 길이가 2 이상인 것들만 토큰화\n",
    "word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<good.a.01: PosScore=0.75 NegScore=0.0>\n",
      "<see.n.01: PosScore=0.0 NegScore=0.0>\n",
      "<again.r.01: PosScore=0.0 NegScore=0.0>\n"
     ]
    }
   ],
   "source": [
    "for word, tag in pos_tag(word_list):\n",
    "    wn_tag = penn_to_wn(tag) # pos_tag -> wordnet으로 바꾸는 함수 사용해서 wn_tag로 표시\n",
    "    if wn_tag:\n",
    "        synsets = list(sentiwordnet.senti_synsets(word, wn_tag))    # 단어 의미 목록을 synsets 변수로 받기\n",
    "        synset = synsets[0] # 단어 의미 목록 중 첫 번째 거 synset 변수로 받기\n",
    "        print(synset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = 0. # 감성지수 초기값 0으로 설정해서 이후 과정에서 도출되는 수치들의 계산 결과에 영향미치지 않도록 함\n",
    "for word, tag in pos_tag(word_list):\n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    if wn_tag:\n",
    "        synsets = list(sentiwordnet.senti_synsets(word, wn_tag))\n",
    "        synset = synsets[0]\n",
    "        sentiment += synset.pos_score() - synset.neg_score()\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = 0.\n",
    "for word, tag in pos_tag(word_list):\n",
    "    wn_tag = penn_to_wn(tag)\n",
    "    if wn_tag:\n",
    "        lemma = lemmatizer.lemmatize(word, wn_tag)  # 품사를 입력하여 표제어 추출기가 보다 정확한 결과를 도출하도록 함\n",
    "        synsets = list(sentiwordnet.senti_synsets(lemma, wn_tag)) # lemma : 표제어 (본래 단어 형태)\n",
    "        synset = synsets[0]\n",
    "        sentiment += synset.pos_score() - synset.neg_score()\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "document = \"I watched this video at a friend's house. I'm glad I did not waste money buying this one. The video cover has a scene from the 1975 movie Capricorn One. The movie starts out with several clips of rocket blow-ups, most not related to manned flight. Sibrel's smoking gun is a short video clip of the astronauts preparing a video broadcast. He edits in his own voice-over instead of letting us listen to what the crew had to say. The video curiously ends with a showing of the Zapruder film. His claims about radiation, shielding, star photography, and others lead me to believe is he extremely ignorant or has some sort of ax to grind against NASA, the astronauts, or American in general. His science is bad, and so is this video.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scene\n",
      "blow-ups\n",
      "Sibrel\n",
      "voice-over\n",
      "Zapruder\n",
      "others\n",
      "부정\n"
     ]
    }
   ],
   "source": [
    "sentiment = 0.0\n",
    "for sentence in sent_tokenize(document):\n",
    "    word_list = [word for word in word_tokenize(sentence) if len(word) > 2]\n",
    "    for word, tag in pos_tag(word_list):\n",
    "        wn_tag = penn_to_wn(tag)\n",
    "        if wn_tag:\n",
    "            lemma = lemmatizer.lemmatize(word, wn_tag)\n",
    "            synsets = list(sentiwordnet.senti_synsets(lemma, wn_tag))\n",
    "            if not synsets:\n",
    "                print(word)\n",
    "                continue\n",
    "            synset = synsets[0]\n",
    "            sentiment += synset.pos_score() - synset.neg_score()\n",
    "print('긍정' if sentiment >= 0 else '부정')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 감성을 계산해주는 함수 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swn_polarity(text):\n",
    "    # 감성 지수 초기화 \n",
    "    sentiment = 0.0\n",
    "    tokens_count = 0\n",
    "    \n",
    "    lemmatizer = WordNetLemmatizer()        # 표제어 추출기\n",
    "    raw_sentences = sent_tokenize(text)     # 문장 토큰화\n",
    "    # 분해된 문장별로 단어 토큰 -> 품사 태깅 후에 SentiSynset 생성 -> 감성 지수 합산 \n",
    "    for raw_sentence in raw_sentences:\n",
    "        # NTLK 기반의 품사 태깅 문장 추출  \n",
    "        word_list = [word for word in word_tokenize(raw_sentence) if len(word) > 2]     # 단어 토큰화\n",
    "        tagged_sentence = pos_tag(word_list)    # (토큰화된 단어, 단어 품사) - 튜플 형태\n",
    "        for word, tag in tagged_sentence:\n",
    "            # WordNet 기반 품사 태깅과 어근 추출\n",
    "            wn_tag = penn_to_wn(tag)\n",
    "            if wn_tag not in (wordnet.NOUN, wordnet.ADJ, wordnet.ADV, wordnet.VERB):\n",
    "                continue                   \n",
    "            lemma = lemmatizer.lemmatize(word, pos=wn_tag)\n",
    "            if not lemma: # lemma == None 이면, 다시 루프 실행\n",
    "                continue\n",
    "            # 어근을 추출한 단어와 WordNet 기반 품사 태깅을 입력해 Synset 객체를 생성. \n",
    "            synsets = wordnet.synsets(lemma, pos=wn_tag)\n",
    "            if not synsets:\n",
    "                continue\n",
    "            # sentiwordnet의 감성 단어 분석으로 감성 synset 추출\n",
    "            # 모든 단어에 대해 긍정 감성 지수는 +로 부정 감성 지수는 -로 합산해 감성 지수 계산. \n",
    "            synset = synsets[0]\n",
    "            swn_synset = sentiwordnet.senti_synset(synset.name())\n",
    "            sentiment += (swn_synset.pos_score() - swn_synset.neg_score())           \n",
    "            tokens_count += 1   # 토큰화 과정이 일어난다면 +1 해준다. \n",
    "    \n",
    "    if not tokens_count:    # 토큰화 과정이 전혀 일어나지 않으면, 즉 입력된 문장의 단어 토큰화가 전혀 일어나지 않은 경우\n",
    "        return 0            # 0을 반환 -> 결과 : 부정\n",
    "    \n",
    "    # 총 score가 0 이상일 경우 긍정(Positive) 1, 그렇지 않을 경우 부정(Negative) 0 반환\n",
    "    return 1 if sentiment >= 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - IMDB 영화평 감성분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"5814_8\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"With all this stuff going down at the moment ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"2381_9\"</td>\n",
       "      <td>1</td>\n",
       "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"7759_3\"</td>\n",
       "      <td>0</td>\n",
       "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  sentiment                                             review\n",
       "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
       "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
       "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell..."
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/labeledTrainData.tsv', sep='\\t', quoting=3)      # 3 : QUOTE-None == 인용구(큰따옴표) 무시\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <br /> 태그 → 공백으로 변환\n",
    "df.review = df.review.str.replace(\"<br />\", \" \")\n",
    "\n",
    "# 구둣점, 숫자 제거 - 영문자가 아닌 것들 공백으로 변환\n",
    "df.review = df.review.str.replace('[^A-Za-z]', ' ').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 3)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1000개 리뷰 분석\n",
    "# df = df.iloc[:1000, :]\n",
    "# df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 18s\n"
     ]
    }
   ],
   "source": [
    "%time df['pred'] = df.review.apply(lambda x : swn_polarity(x))  # 위에서 만든 감성지수 계산하는 함수 사용해서 긍정/부정 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.62568"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score  # 실제 감성지수(sentiment)와 예측값(pred) 비교 -> 정확도 도출\n",
    "accuracy_score(df.sentiment, df.pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### < VADER Lexicon을 이용한 감성 분석 >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.13, 'neu': 0.743, 'pos': 0.127, 'compound': -0.7943}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer # 클래스\n",
    "\n",
    "senti_analyzer = SentimentIntensityAnalyzer()   # 객체 생성\n",
    "senti_score = senti_analyzer.polarity_scores(df.review[0])  # polarity_scores() : -1 ~ 1 사잇값\n",
    "senti_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vader_polarity(document, threshold=0.1):            # threshold 값 0.1  -> threshold(임계값) : 긍정과 부정을 나누는 기준점\n",
    "    score = senti_analyzer.polarity_scores(document)\n",
    "    return 1 if score['compound'] >= threshold else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 58.1 s\n"
     ]
    }
   ],
   "source": [
    "%time df['vader_pred'] = df.review.apply(lambda x : vader_polarity(x, 0.1))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.69556"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df.sentiment, df.vader_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예측 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>pred</th>\n",
       "      <th>vader_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  pred  vader_pred\n",
       "0          1     1           0\n",
       "1          1     1           1\n",
       "2          0     0           0\n",
       "3          0     0           1\n",
       "4          1     0           1\n",
       "5          1     0           1\n",
       "6          0     1           0\n",
       "7          0     0           0\n",
       "8          0     0           1\n",
       "9          1     1           1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf = df[['sentiment', 'pred', 'vader_pred']]\n",
    "cdf.head(10)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
