{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 영화평 감성분석 _ 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 데이터 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 데이터 전처리\n",
    "    - Null 데이터 확인 및 제거\n",
    "    - 중복 데이터 확인 및 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 텍스트 전처리\n",
    "    - 한글 이외 문자 공백 처리하고 strip\n",
    "    - '' 와 같은 값 Null 값으로 변경 후 제거 (np.nan)\n",
    "    - 전처리 완료 후 데이터 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 완료해서 저장한 데이터 불러오기\n",
    "train_df = pd.read_csv('data/naver_movie_train_전처리완료.csv', sep='\\t')\n",
    "test_df = pd.read_csv('data/naver_movie_test_전처리완료.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 한글 처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "scores = joblib.load('data/scores.pkl') # Soynlp 로 토큰화 -> 학습 결과 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.tokenizer import MaxScoreTokenizer\n",
    "max_tokenizer = MaxScoreTokenizer(scores) # 학습한 데이터 넣어서 토큰화 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어(stopwords) 리스트 만들기\n",
    "# 출처: https://www.kci.go.kr/kciportal/ci/sereArticleSearch/ciSereArtiView.kci?sereArticleSearchBean.artiId=ART002390885\n",
    "\n",
    "with open('data/한국어조사.txt', encoding='utf-8') as file:\n",
    "    stopwords = file.read()\n",
    "\n",
    "stop_list = stopwords.split(', ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'혼란 시대. 과학 부정 하는 정치 병자 들에게 날리는 불꽃혜성 인류 종말쑈! 인류의 생존 경제 정치적 도박의 소재로 삼는 탐욕스런 자본과 정치 병자들이 결탁하여 감상적인 대중을 선동할때, 이미 지구 이성적 인류는 멸종위기 종. 결국 자본의 탐욕과 결합한 정치 병자들을 치유하기 위해 서라도 합리적 과학 근거 이성의 정치 끝 포기하지 사수 해야 한다 .'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아무 텍스트 가져와서 한글 처리 과정 해보기\n",
    "text = '혼란의 시대. 과학을 부정하는 정치병자들에게 날리는 불꽃혜성 인류 종말쑈! 인류의 생존까지도 경제적 정치적 도박의 소재로 삼는 탐욕스런 자본과 정치병자들이 결탁하여 감상적인 대중을 선동할때, 이미 이 지구에서 이성적 인류는 멸종위기종. 결국 자본의 탐욕과 결합한 정치병자들을 치유하기 위해서라도 우리는 합리적 과학에 근거한 이성의 정치를 끝까지 포기하지 말고 사수해야 한다.'\n",
    "word_list = max_tokenizer.tokenize(text)\n",
    "word_list = [word for word in word_list if word not in stop_list]\n",
    "review = ' '.join(word_list)\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. X_train, X_test, y_train, y_test 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaaf5a5c26974f42965af76428e62e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/145393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# X_train\n",
    "from tqdm.notebook import tqdm\n",
    "X_train = []\n",
    "for document in tqdm(train_df.document):\n",
    "    word_list = max_tokenizer.tokenize(document) # 토큰화\n",
    "    word_list = [word for word in word_list if word not in stop_list] # 불용어 제거\n",
    "    review = ' '.join(word_list)\n",
    "    X_train.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "051593e6b4d0415a84cd74bf493116ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48852 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# X_test\n",
    "from tqdm.notebook import tqdm\n",
    "X_test = []\n",
    "for document in tqdm(test_df.document):\n",
    "    word_list = max_tokenizer.tokenize(document) # 토큰화\n",
    "    word_list = [word for word in word_list if word not in stop_list] # 불용어 제거\n",
    "    review = ' '.join(word_list)\n",
    "    X_test.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train, y_test \n",
    "y_train = train_df.label.values\n",
    "y_test = test_df.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Feature 변환 - CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cvect = CountVectorizer()\n",
    "cvect.fit(X_train)\n",
    "X_trained = cvect.transform(X_train)\n",
    "X_tested = cvect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((145393, 159347), (48852, 159347))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trained.shape, X_tested.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 모델 생성 / 학습 / 평가 --- 분류기 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8291369851797266"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lrc = LogisticRegression(random_state=2022)\n",
    "lrc.fit(X_trained, y_train)\n",
    "lrc.score(X_tested, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8244493572422829"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc = SVC()\n",
    "svc.fit(X_trained, y_train)\n",
    "svc.score(X_tested, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6931138950298862"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_trained, y_train)\n",
    "knn.score(X_tested, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7974494391222468"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier(random_state=2021)\n",
    "rfc.fit(X_trained, y_train)\n",
    "rfc.score(X_tested, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voc = VotingClassifier(\n",
    "    estimators=[('LRC', lrc),('SVC', svc), ('KNN', knn)], voting='hard'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8266396462785557"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc.fit(X_trained, y_train)\n",
    "voc.score(X_tested, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((145393, 900051), (48852, 900051))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvect2 = CountVectorizer(min_df=1, max_df=0.9, ngram_range=(1,2))\n",
    "cvect2.fit(X_train)\n",
    "X_trained2 = cvect2.transform(X_train)\n",
    "X_tested2 = cvect2.transform(X_test)\n",
    "X_trained2.shape, X_tested2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.846045197740113"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_trained2, y_train)\n",
    "nb.score(X_tested2, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyzer': 'word',\n",
       " 'binary': False,\n",
       " 'decode_error': 'strict',\n",
       " 'dtype': numpy.int64,\n",
       " 'encoding': 'utf-8',\n",
       " 'input': 'content',\n",
       " 'lowercase': True,\n",
       " 'max_df': 1.0,\n",
       " 'max_features': None,\n",
       " 'min_df': 1,\n",
       " 'ngram_range': (1, 1),\n",
       " 'preprocessor': None,\n",
       " 'stop_words': None,\n",
       " 'strip_accents': None,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tokenizer': None,\n",
       " 'vocabulary': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvect.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('cvect', CountVectorizer()),\n",
    "    ('lrc', LogisticRegression(random_state=2022))\n",
    "])\n",
    "params = {\n",
    "    'cvect__ngram_range' : [(1,1), (1,2)],\n",
    "    'cvect__max_df' : [0.8, 0.85, 0.9],  # 소수점 == % / 정수 == 단어수\n",
    "    'cvect__min_df' : [0, 1, 2],\n",
    "    'lrc__C' : [0.1, 0.5, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('cvect', CountVectorizer()),\n",
       "                                       ('lrc',\n",
       "                                        LogisticRegression(random_state=2022))]),\n",
       "             param_grid={'cvect__max_df': [0.8, 0.85, 0.9],\n",
       "                         'cvect__min_df': [0, 1, 2],\n",
       "                         'cvect__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'lrc__C': [0.1, 0.5, 1]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_pipe = GridSearchCV(\n",
    "    pipeline, param_grid=params, scoring='accuracy', cv=3\n",
    ")\n",
    "%time grid_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvect__max_df': 0.8,\n",
       " 'cvect__min_df': 0,\n",
       " 'cvect__ngram_range': (1, 2),\n",
       " 'lrc__C': 1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_pipe.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8383894211086547"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_pipe.best_estimator_.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('cvect', CountVectorizer()),\n",
    "    ('lrc', LogisticRegression(random_state=2022))\n",
    "])\n",
    "params = {\n",
    "    'cvect__ngram_range' : [(1,1), (1,2)],\n",
    "    'cvect__max_df' : [0.9, 0.99],  # 소수점 == % / 정수 == 단어수\n",
    "    'cvect__min_df' : [1, 5],\n",
    "    'svc__C' : [0.1, 0.5, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'auto',\n",
       " 'leaf_size': 30,\n",
       " 'metric': 'minkowski',\n",
       " 'metric_params': None,\n",
       " 'n_jobs': None,\n",
       " 'n_neighbors': 5,\n",
       " 'p': 2,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('cvect', CountVectorizer()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "params = {\n",
    "    'cvect__ngram_range' : [(1,1), (1,2)],\n",
    "    'cvect__max_df' : [0.9, 0.99],  # 소수점 == % / 정수 == 단어수\n",
    "    'cvect__min_df' : [1, 5],\n",
    "    'knn__n_neighbors' : [5, 7, 11],\n",
    "    'knn__p' : [1, 2]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5h 37min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('cvect', CountVectorizer()),\n",
       "                                       ('knn', KNeighborsClassifier())]),\n",
       "             param_grid={'cvect__max_df': [0.9, 0.99], 'cvect__min_df': [1, 5],\n",
       "                         'cvect__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'knn__n_neighbors': [5, 7, 11], 'knn__p': [1, 2]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_pipe = GridSearchCV(\n",
    "    pipeline, param_grid=params, scoring='accuracy', cv=3\n",
    ")\n",
    "%time grid_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvect__max_df': 0.9,\n",
       " 'cvect__min_df': 5,\n",
       " 'cvect__ngram_range': (1, 2),\n",
       " 'knn__n_neighbors': 5,\n",
       " 'knn__p': 1}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_pipe.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7023868009498075"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_pipe.best_estimator_.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
