{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 영화평 감성분석 _ 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 데이터 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 데이터 전처리\n",
    "    - Null 데이터 확인 및 제거\n",
    "    - 중복 데이터 확인 및 제거"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 텍스트 전처리\n",
    "    - 한글 이외 문자 공백 처리하고 strip\n",
    "    - '' 와 같은 값 Null 값으로 변경 후 제거 (np.nan)\n",
    "    - 전처리 완료 후 데이터 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 완료해서 저장한 데이터 불러오기\n",
    "train_df = pd.read_csv('data/naver_movie_train_전처리완료.csv', sep='\\t')\n",
    "test_df = pd.read_csv('data/naver_movie_test_전처리완료.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 한글 처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "scores = joblib.load('data/scores.pkl') # Soynlp 로 토큰화 -> 학습 결과 불러오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from soynlp.tokenizer import MaxScoreTokenizer\n",
    "max_tokenizer = MaxScoreTokenizer(scores) # 학습한 데이터 넣어서 토큰화 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불용어(stopwords) 리스트 만들기\n",
    "# 출처: https://www.kci.go.kr/kciportal/ci/sereArticleSearch/ciSereArtiView.kci?sereArticleSearchBean.artiId=ART002390885\n",
    "\n",
    "with open('data/한국어조사.txt', encoding='utf-8') as file:\n",
    "    stopwords = file.read()\n",
    "\n",
    "stop_list = stopwords.split(', ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'혼란 시대. 과학 부정 하는 정치 병자 들에게 날리는 불꽃혜성 인류 종말쑈! 인류의 생존 경제 정치적 도박의 소재로 삼는 탐욕스런 자본과 정치 병자들이 결탁하여 감상적인 대중을 선동할때, 이미 지구 이성적 인류는 멸종위기 종. 결국 자본의 탐욕과 결합한 정치 병자들을 치유하기 위해 서라도 합리적 과학 근거 이성의 정치 끝 포기하지 사수 해야 한다 .'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 아무 텍스트 가져와서 한글 처리 과정 해보기\n",
    "text = '혼란의 시대. 과학을 부정하는 정치병자들에게 날리는 불꽃혜성 인류 종말쑈! 인류의 생존까지도 경제적 정치적 도박의 소재로 삼는 탐욕스런 자본과 정치병자들이 결탁하여 감상적인 대중을 선동할때, 이미 이 지구에서 이성적 인류는 멸종위기종. 결국 자본의 탐욕과 결합한 정치병자들을 치유하기 위해서라도 우리는 합리적 과학에 근거한 이성의 정치를 끝까지 포기하지 말고 사수해야 한다.'\n",
    "word_list = max_tokenizer.tokenize(text)\n",
    "word_list = [word for word in word_list if word not in stop_list]\n",
    "review = ' '.join(word_list)\n",
    "review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. X_train, X_test, y_train, y_test 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8d0425cda444959bd83db5b1094a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/145393 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# X_train\n",
    "from tqdm.notebook import tqdm\n",
    "X_train = []\n",
    "for document in tqdm(train_df.document):\n",
    "    word_list = max_tokenizer.tokenize(document) # 토큰화\n",
    "    word_list = [word for word in word_list if word not in stop_list] # 불용어 제거\n",
    "    review = ' '.join(word_list)\n",
    "    X_train.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88dcb5b8520b4608b5228b466664cace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48852 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# X_test\n",
    "from tqdm.notebook import tqdm\n",
    "X_test = []\n",
    "for document in tqdm(test_df.document):\n",
    "    word_list = max_tokenizer.tokenize(document) # 토큰화\n",
    "    word_list = [word for word in word_list if word not in stop_list] # 불용어 제거\n",
    "    review = ' '.join(word_list)\n",
    "    X_test.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train, y_test \n",
    "y_train = train_df.label.values\n",
    "y_test = test_df.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Feature 변환 - CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cvect = CountVectorizer()\n",
    "cvect.fit(X_train)\n",
    "X_trained = cvect.transform(X_train)\n",
    "X_tested = cvect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((145393, 159347), (48852, 159347))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trained.shape, X_tested.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 모델 생성 / 학습 / 평가 --- 분류기 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8291369851797266"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lrc = LogisticRegression(random_state=2022)\n",
    "lrc.fit(X_trained, y_train)\n",
    "lrc.score(X_tested, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# svc = SVC()\n",
    "# svc.fit(X_trained, y_train)\n",
    "# svc.score(X_tested, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# knn = KNeighborsClassifier()\n",
    "# knn.fit(X_trained, y_train)\n",
    "# knn.score(X_tested, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# rfc = RandomForestClassifier(random_state=2021)\n",
    "# rfc.fit(X_trained, y_train)\n",
    "# rfc.score(X_tested, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import VotingClassifier\n",
    "# \n",
    "# voc = VotingClassifier(\n",
    "#     estimators=[('LRC', lrc),('SVC', svc), ('KNN', knn)], voting='hard'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# voc.fit(X_trained, y_train)\n",
    "# voc.score(X_tested, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((145393, 900051), (48852, 900051))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvect2 = CountVectorizer(min_df=1, max_df=0.9, ngram_range=(1,2))\n",
    "cvect2.fit(X_train)\n",
    "X_trained2 = cvect2.transform(X_train)\n",
    "X_tested2 = cvect2.transform(X_test)\n",
    "X_trained2.shape, X_tested2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.846045197740113"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_trained2, y_train)\n",
    "nb.score(X_tested2, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyzer': 'word',\n",
       " 'binary': False,\n",
       " 'decode_error': 'strict',\n",
       " 'dtype': numpy.int64,\n",
       " 'encoding': 'utf-8',\n",
       " 'input': 'content',\n",
       " 'lowercase': True,\n",
       " 'max_df': 1.0,\n",
       " 'max_features': None,\n",
       " 'min_df': 1,\n",
       " 'ngram_range': (1, 1),\n",
       " 'preprocessor': None,\n",
       " 'stop_words': None,\n",
       " 'strip_accents': None,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tokenizer': None,\n",
       " 'vocabulary': None}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvect.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('cvect', CountVectorizer()),\n",
    "    ('lrc', LogisticRegression(random_state=2022))\n",
    "])\n",
    "params = {\n",
    "    'cvect__ngram_range' : [(1,1), (1,2), (1,3)],\n",
    "    'cvect__max_df' : [0.9, 0.99],  # 소수점 == % / 정수 == 단어수\n",
    "    'cvect__min_df' : [1, 3],\n",
    "    'lrc__C' : [1, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_pipe = GridSearchCV(\n",
    "    pipeline, param_grid=params, scoring='accuracy', cv=3\n",
    ")\n",
    "%time grid_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_pipe.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_pipe.best_estimator_.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
